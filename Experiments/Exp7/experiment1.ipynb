{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 7: TRo Journal\n",
    "---\n",
    "\n",
    "In this experiment, the generalization of cloth models to unseen T-shirts of the mannequin is verified. The evaluation is performed using RMSE, NRMSE, Pearson correlation as the parameters. In this notebook, the MRD cloth models are trained excluding one T-shirt for test inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the modules\n",
    "import sys\n",
    "import GPy\n",
    "import csv\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import scipy.stats as stats\n",
    "import sklearn.metrics as metrics\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load all the files and create Data\n",
    "trackPath = '../Data/Tracks/'\n",
    "mocapPath = '../Data/MocapData/'\n",
    "kinectPath = '../Data/KinectData/'\n",
    "\n",
    "nShr = 4\n",
    "nPos = 6\n",
    "names = []\n",
    "for sInd in range(nShr):\n",
    "    for pInd in range(nPos):\n",
    "        names.append('K1S%dP%dT1' % (sInd+1,pInd+1))\n",
    "\n",
    "# create directory for results\n",
    "dName = '../Models/Exp7'\n",
    "if not os.path.exists(dName):\n",
    "    os.makedirs(dName)\n",
    "        \n",
    "Data = pickle.load(open('../Data/Data.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the overall parameters for bgplvm\n",
    "qDim = 15\n",
    "\n",
    "# dimensions for kinect and mocap\n",
    "qDims = [10,5]\n",
    "qDVals = [np.arange(0,qDims[0]), np.arange(qDims[0],qDims[0]+qDims[1])]\n",
    "\n",
    "# set the number of inducing inputs\n",
    "nInducing = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# main loop\n",
    "samplingFreq = 2\n",
    "\n",
    "# optimization variables\n",
    "SNR0 = 1000\n",
    "SNR1 = 100\n",
    "trainIters = 1500\n",
    "initMod0Iters = 500\n",
    "initMod1Iters = 500\n",
    "initVardistIters = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loop over the kinect keys\n",
    "kinectExt = 'C'\n",
    "kinectDim = 7500\n",
    "kinectKey = 'Cloud'\n",
    "\n",
    "mocapDim = 8\n",
    "mocapExt = 'T'\n",
    "mocapKey = 'TopCoord'\n",
    "    \n",
    "keys = [kinectKey,mocapKey]\n",
    "dims = [kinectDim, mocapDim]\n",
    "YNames = [kinectKey, mocapKey]\n",
    "expName = '%s%s' % (kinectExt,mocapExt)\n",
    "\n",
    "ValInd = [[6,7,14,15,22,23],[4,5,12,13,20,21],[2,3,10,11,18,19],[0,1,8,9,16,17]]\n",
    "TestInd = [[0,1,2,3,4,5],[6,7,8,9,10,11],[12,13,14,15,16,17],[18,19,20,21,22,23]]\n",
    "TrainInd = [[8,9,16,17,18,19],[0,1,14,15,22,23],[4,5,6,7,20,21],[2,3,10,11,12,13]]\n",
    "\n",
    "for sInd in range(nShirts):\n",
    "    valData = {}\n",
    "    testData = {}\n",
    "    trainData = {}\n",
    "\n",
    "    valInd = ValInd[sInd]\n",
    "    testInd = TestInd[sInd]\n",
    "    trainInd = TrainInd[sInd]\n",
    "    \n",
    "    print 'Cycle:%d' % (sInd+1)\n",
    "    print valInd, testInd, trainInd\n",
    "    \n",
    "    for key,dim in zip(keys,dims):\n",
    "        trD = np.empty((0,dim))\n",
    "        for ind in trainInd:\n",
    "            trD = np.concatenate((trD,Data[names[ind]][key][::samplingFreq,:]),axis=0)\n",
    "        trainData[key] = trD\n",
    "        \n",
    "    # choosing the training dataset\n",
    "    nSamples = trainData[kinectKey].shape[0]\n",
    "    trainList = [trainData[kinectKey], trainData[mocapKey]]\n",
    "    \n",
    "    # initializing the latent space \n",
    "    scales = []\n",
    "    inputX = np.zeros((nSamples,qDim))\n",
    "\n",
    "    for qD,qDV,Y in zip(qDims, qDVals, trainList):\n",
    "        x,frcs = GPy.util.initialization.initialize_latent('PCA',qD, Y)\n",
    "        scales.extend(frcs)\n",
    "        inputX[:,qDV] = x\n",
    "    \n",
    "    scales = np.asarray(scales)\n",
    "    print scales\n",
    "    \n",
    "    # setting up the kernel\n",
    "    mrdKernels = []\n",
    "\n",
    "    for Y in trainList:\n",
    "        mrdKernels.append(GPy.kern.RBF(qDim, variance=1., lengthscale=1./scales, ARD = True))\n",
    "        \n",
    "    # initializing MRD model\n",
    "    mrdModel = GPy.models.MRD(trainList, input_dim=qDim, num_inducing=nInducing, kernel=mrdKernels, \n",
    "                              X=inputX, name='%s%d%d' % (expName,sInd,pInd+1))\n",
    "    print 'Setup Model!'\n",
    "    \n",
    "    # Phase 1: Optimizaition by fixing variance parameters\n",
    "    var0 = mrdModel.Y0.Y.var()\n",
    "    var1 = mrdModel.Y1.Y.var()\n",
    "\n",
    "    mrdModel.Y0.rbf.variance.fix(var0)\n",
    "    mrdModel.Y1.rbf.variance.fix(var1)\n",
    "\n",
    "    mrdModel.Y0.Gaussian_noise.variance.fix(var0/SNR0)\n",
    "    mrdModel.Y1.Gaussian_noise.variance.fix(var1/SNR1)\n",
    "\n",
    "    mrdModel.optimize(messages=True, max_iters=initVardistIters)\n",
    "    \n",
    "    # Phase 2: Optimize each model individually\n",
    "\n",
    "    # constrain space 0\n",
    "    mrdModel.Y1.constrain_fixed()\n",
    "    mrdModel.optimize(messages=True, max_iters=initMod0Iters)\n",
    "\n",
    "    # constrain space 1\n",
    "    mrdModel.Y0.constrain_fixed()\n",
    "    mrdModel.Y1.unconstrain_fixed()\n",
    "    mrdModel.Y1.rbf.variance.fix(var1)\n",
    "    mrdModel.Y1.Gaussian_noise.variance.fix(var1/SNR1)\n",
    "    mrdModel.optimize(messages=True, max_iters=initMod1Iters)\n",
    "    \n",
    "    # Phase 3: Optimize the model without any constraints\n",
    "\n",
    "    # training without constraints\n",
    "    mrdModel.Y0.unconstrain_fixed()\n",
    "    mrdModel.Y1.unconstrain_fixed()\n",
    "    mrdModel.optimize(messages=True, max_iters=trainIters)\n",
    "    \n",
    "    print 'Training Done!'\n",
    "    \n",
    "    # plot the learned model\n",
    "    mrdModel.plot_scales(sharex=True,sharey=False,titles=YNames)\n",
    "    mrdModel.plot_latent(which_indices=[0,1])\n",
    "    \n",
    "    # save the model\n",
    "    mrdModel = pickle.dump(mrdModel, open('../Models/Exp7/%s%d.p' % (expName,sInd+1),'wb'))\n",
    "    \n",
    "    print 'Saving Done!'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
