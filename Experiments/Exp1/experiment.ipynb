{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: TRo Journal\n",
    "---\n",
    "\n",
    "Compare the performance of BGPLVM with a linear latent variable model such as PCA for cloth state estimation. Experimental results show that BGPLVM has significantly better performance and generalization capability with respect to PCA.\n",
    "\n",
    "The metrics for evaluation are RMS error, normalized RMS error and pearson correlation. The significance was evaluated using Wilcoxon rank sum test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the modules\n",
    "import sys\n",
    "import GPy\n",
    "import csv\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import matplotlib.cm as cm\n",
    "import scipy.stats as stats\n",
    "from tabulate import tabulate\n",
    "from GPy.plotting import Tango\n",
    "import sklearn.metrics as metrics\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load all the files and create Data\n",
    "trackPath = '../Data/Tracks/'\n",
    "mocapPath = '../Data/MocapData/'\n",
    "kinectPath = '../Data/KinectData/'\n",
    "\n",
    "names = ['K1S1P1T1','K1S1P2T1','K1S1P3T1','K1S1P4T1','K1S1P5T1','K1S1P6T1',\n",
    "         'K1S2P2T1','K1S2P3T1','K1S2P4T1','K1S3P2T1','K1S3P3T1','K1S3P4T1']\n",
    "\n",
    "nTypes = 9\n",
    "\n",
    "dataFormats = ['','ESF','Cloud','Color','Depth','Marker','CircleParam','CircleMarker','TopCoord']\n",
    "dataKeys = ['Time','ESF','Cloud','Color','Depth','Marker','CircleParam','CircleMarker','TopCoord']\n",
    "\n",
    "paths = [trackPath, kinectPath, kinectPath, kinectPath, kinectPath, mocapPath, mocapPath, mocapPath, mocapPath]\n",
    "\n",
    "# read all the file names and save to dicts\n",
    "Data = {}\n",
    "# loop over all names\n",
    "for fileName in names:\n",
    "    data = {}\n",
    "    for ind in range(nTypes):\n",
    "        dataName = paths[ind] + fileName + dataFormats[ind] \n",
    "        reader = csv.reader(open(dataName,\"rb\"), delimiter=',')\n",
    "\n",
    "        d = np.array(list(reader))\n",
    "        if ind in [3,4]:\n",
    "            data[dataKeys[ind]] = d.astype('int')\n",
    "        else:\n",
    "            data[dataKeys[ind]] = d.astype('float')        \n",
    "    Data[fileName] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create train, val and test data\n",
    "trainNames = ['K1S1P2T1','K1S1P3T1','K1S1P4T1','K1S1P5T1','K1S1P6T1']\n",
    "testNames = ['K1S1P1T1','K1S2P2T1','K1S2P3T1','K1S2P4T1','K1S3P2T1','K1S3P3T1','K1S3P4T1']\n",
    "\n",
    "samplingFreq = 4\n",
    "\n",
    "dim = 7500\n",
    "key = 'Cloud'\n",
    "\n",
    "testSize = 0\n",
    "trainSize = 0\n",
    "testData = []\n",
    "testSizes = []\n",
    "trainTraj = []\n",
    "trainSizes = []\n",
    "trainData = np.empty((0,dim))    \n",
    "\n",
    "for fileName in trainNames:\n",
    "    trainTraj.append(Data[fileName][key][::samplingFreq,:])\n",
    "    trainSizes.append(trainTraj[-1].shape[0])\n",
    "    trainData = np.concatenate((trainData,Data[fileName][key][::samplingFreq,:]),axis=0)\n",
    "trainSize += trainData.shape[0]\n",
    "    \n",
    "for fileName in testNames:\n",
    "    testData.append(Data[fileName][key][::samplingFreq,:])\n",
    "    testSizes.append(testData[-1].shape[0])\n",
    "    testSize += testSizes[-1]\n",
    "print trainSizes, testSizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Model Training\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training Cloud BGPLVM Model\n",
    "\n",
    "# model name\n",
    "expName = 'bgplvmModel'\n",
    "\n",
    "# set the overall parameters for bgplvm\n",
    "qDim = 15\n",
    "nSamples = trainData.shape[0]\n",
    "\n",
    "# set the number of inducing inputs\n",
    "nInducing = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=qDim)\n",
    "pca.fit(trainData)\n",
    "\n",
    "scalesPCA = pca.explained_variance_ratio_\n",
    "scalesPCA = scalesPCA/scalesPCA.max()\n",
    "\n",
    "trainX = pca.transform(trainData)\n",
    "trainOut = pca.inverse_transform(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setting up the kernel\n",
    "kernel = GPy.kern.RBF(qDim, variance=1., lengthscale=1./scalesPCA, ARD = True)\n",
    "\n",
    "# exepriment with different X initializations\n",
    "bgplvmModel = GPy.models.BayesianGPLVM(trainData,input_dim=qDim,num_inducing=nInducing,kernel=kernel,X=trainX)\n",
    "\n",
    "# Phase 1: Optimizaition by fixing variance parameters\n",
    "SNR = 1000\n",
    "var = bgplvmModel.Y.var()\n",
    "\n",
    "bgplvmModel.rbf.variance.fix(var)\n",
    "bgplvmModel.Gaussian_noise.variance.fix(var/SNR)\n",
    "\n",
    "initVardistIters = 2000\n",
    "bgplvmModel.optimize(messages=True, max_iters=initVardistIters)\n",
    "\n",
    "# Phase 2: Optimize the model without any constraints\n",
    "\n",
    "# training without constraints\n",
    "trainIters = 1000\n",
    "bgplvmModel.unconstrain_fixed()\n",
    "bgplvmModel.optimize(messages=True, max_iters=trainIters)\n",
    "\n",
    "# Save the model to file\n",
    "pickle.dump(bgplvmModel,open('../Models/model.p','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to compute pearson correlation and nrmse\n",
    "def computeMetrics(predData, trueData):\n",
    "    nDims = trueData.shape[1]\n",
    "    out1 = np.nonzero(trueData.std(axis=0))\n",
    "    out2 = np.nonzero(predData.std(axis=0))\n",
    "    \n",
    "    # remove the dimensions without information\n",
    "    validDims = np.intersect1d(out1[0],out2[0])\n",
    "    predCData = predData[:, validDims]\n",
    "    trueCData = trueData[:, validDims]\n",
    "    \n",
    "    # compute rms err\n",
    "    err1 = np.divide(np.sqrt(metrics.mean_squared_error(predCData,trueCData,multioutput='raw_values')), trueCData.max(axis=0) - trueCData.min(axis=0))\n",
    "    err2 = np.sqrt(metrics.mean_squared_error(predCData,trueCData,multioutput='raw_values'))    \n",
    "    \n",
    "    # compute pearson correlation\n",
    "    corr = np.zeros((2,validDims.shape[0]))\n",
    "    for d in range(validDims.shape[0]):\n",
    "        corr[0,d],corr[1,d] = stats.pearsonr(predCData[:,d],trueCData[:,d])\n",
    "    \n",
    "    return err1.mean(), err2.mean(), corr.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = {}\n",
    "W[5] = {'max':15, 'min':0, 'p':0.05}\n",
    "W[6] = {'max':21, 'min':0, 'p':0.025}\n",
    "W[7] = {'max':28, 'min':0, 'p':0.01}\n",
    "\n",
    "# function to compute wilcoxon metric for one-sided x > y, greater than test\n",
    "def wilcoxon(x,y):\n",
    "    # convert to numpy arrays\n",
    "    x,y = map(np.asarray, (x,y))\n",
    "    \n",
    "    # compute differences\n",
    "    d = x - y\n",
    "    \n",
    "    # remove zero differences\n",
    "    d = np.compress(np.not_equal(d, 0), d, axis=-1)\n",
    "    \n",
    "    # compute rank of differences\n",
    "    r = stats.rankdata(abs(d))\n",
    "    \n",
    "    # compute sum of ranked differences\n",
    "    T = np.sum((d > 0)*r, axis=0)\n",
    "    \n",
    "    # significant or not significant\n",
    "    n = d.shape[0]\n",
    "    \n",
    "    # assign significance\n",
    "    if (T >= W[n]['max'] or T <= W[n]['min']):\n",
    "        result = W[n]['p']\n",
    "    else:\n",
    "        result = None\n",
    "        \n",
    "    # return statistic and result\n",
    "    return T, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# performing latent point inference\n",
    "bgplvmModel = pickle.load(open('../Models/model.p','rb'))\n",
    "\n",
    "trainX = np.zeros((trainData.shape[0],qDim))\n",
    "trainOut = np.zeros(trainData.shape)\n",
    "for i in range(trainData.shape[0]):\n",
    "    [xPredict, infX] = bgplvmModel.infer_newX(np.atleast_2d(trainData[i,:]), optimize=False)\n",
    "    trainX[i,:] = xPredict.mean\n",
    "    trainOut[i,:],_ = bgplvmModel.predict(np.atleast_2d(trainX[i,:]))\n",
    "    sys.stdout.write('.')\n",
    "sys.stdout.write('\\n')\n",
    "\n",
    "bgplvmX = [trainX]\n",
    "bgplvmOut = [trainOut]\n",
    "\n",
    "# loop over test trials\n",
    "bgplvmMainX = np.zeros((0,qDim))\n",
    "bgplvmMainOut = np.zeros((0,dim))\n",
    "for ind in range(len(testData)):\n",
    "    testX = np.zeros((testData[ind].shape[0],qDim))\n",
    "    testOut = np.zeros(testData[ind].shape)\n",
    "    for i in range(testData[ind].shape[0]):\n",
    "        [xPredict, infX] = bgplvmModel.infer_newX(np.atleast_2d(testData[ind][i,:]), optimize=True)\n",
    "        testX[i,:] = xPredict.mean\n",
    "        testOut[i,:],_ = bgplvmModel.predict(np.atleast_2d(xPredict.mean))\n",
    "        sys.stdout.write('.')\n",
    "    \n",
    "    bgplvmX.append(testX.copy())\n",
    "    bgplvmOut.append(testOut.copy())\n",
    "    \n",
    "    bgplvmMainX = np.concatenate((bgplvmMainX,testX),axis=0)\n",
    "    bgplvmMainOut = np.concatenate((bgplvmMainOut,testOut),axis=0)\n",
    "    sys.stdout.write('\\n')\n",
    "    \n",
    "scalesBGPLVM = bgplvmModel.kern.input_sensitivity(summarize=False)\n",
    "scalesBGPLVM =  scalesBGPLVM/scalesBGPLVM.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=qDim)\n",
    "pca.fit(trainData)\n",
    "\n",
    "scalesPCA = pca.explained_variance_ratio_\n",
    "scalesPCA = scalesPCA/scalesPCA.max()\n",
    "\n",
    "trainX = pca.transform(trainData)\n",
    "trainOut = pca.inverse_transform(trainX)\n",
    "\n",
    "pcaX = [trainX]\n",
    "pcaOut = [trainOut]\n",
    "\n",
    "pcaMainX = np.zeros((0,qDim))\n",
    "pcaMainOut = np.zeros((0,dim))\n",
    "\n",
    "for ind in range(len(testData)):\n",
    "    testX = pca.transform(testData[ind])\n",
    "    testOut = pca.inverse_transform(testX)\n",
    "    \n",
    "    pcaX.append(testX.copy())\n",
    "    pcaOut.append(testOut.copy())\n",
    "\n",
    "    pcaMainX = np.concatenate((pcaMainX,testX),axis=0)\n",
    "    pcaMainOut = np.concatenate((pcaMainOut,testOut),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trueOut = [trainData] + testData\n",
    "\n",
    "predictData = {}\n",
    "predictData['PCA'] = pcaOut\n",
    "predictData['True'] = trueOut\n",
    "predictData['BGPLVM'] = bgplvmOut\n",
    "\n",
    "latentData = {}\n",
    "latentData['PCA'] = pcaMainX\n",
    "latentData['PCATrain'] = trainX\n",
    "latentData['BGPLVM'] = bgplvmMainX\n",
    "latentData['PCAScales'] = scalesPCA\n",
    "latentData['BGPLVMScales'] = scalesBGPLVM\n",
    "\n",
    "pickle.dump(latentData,open('../Result/Exp1/latentData.p','wb'))\n",
    "pickle.dump(predictData,open('../Result/Exp1/predictData.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "latentData = pickle.load(open('../Result/Exp1/latentData.p','rb'))\n",
    "predictData = pickle.load(open('../Result/Exp1/predictData.p','rb'))\n",
    "\n",
    "# initialize variables to compute metrics\n",
    "nTrials = len(predictData['PCA'])\n",
    "dims = predictData['PCA'][0].shape[1]\n",
    "results = {'PCA':{'Err':[],'Corr':[],'pval':[],'NormErr':[]}, \n",
    "           'BGPLVM':{'Err':[],'Corr':[],'pval':[],'NormErr':[]}}\n",
    "\n",
    "# loop over the trials\n",
    "for nTrial in range(nTrials):\n",
    "    pcaData = predictData['PCA'][nTrial]\n",
    "    trueData = predictData['True'][nTrial]\n",
    "    bgplvmData = predictData['BGPLVM'][nTrial]\n",
    "\n",
    "    pcaNormErr, pcaErr, pcaCorr = computeMetrics(pcaData,trueData)\n",
    "    bgplvmNormErr, bgplvmErr, bgplvmCorr = computeMetrics(bgplvmData,trueData)\n",
    "    \n",
    "    results['PCA']['Err'].append(pcaErr)\n",
    "    results['PCA']['Corr'].append(pcaCorr[0])\n",
    "    results['PCA']['pval'].append(pcaCorr[1])\n",
    "    results['PCA']['NormErr'].append(pcaNormErr)\n",
    "    \n",
    "    results['BGPLVM']['Err'].append(bgplvmErr)\n",
    "    results['BGPLVM']['Corr'].append(bgplvmCorr[0])\n",
    "    results['BGPLVM']['pval'].append(bgplvmCorr[1])\n",
    "    results['BGPLVM']['NormErr'].append(bgplvmNormErr)\n",
    "\n",
    "    print 'Trial: %d' % nTrial\n",
    "    print 'Errs: PCA: %f, BGPLVM: %f' % (pcaErr,bgplvmErr)\n",
    "    print 'Corrs: PCA: %f, BGPLVM: %f' % (pcaCorr[0],bgplvmCorr[0])\n",
    "    print 'Norm Errs: PCA: %f, BGPLVM: %f' % (pcaNormErr,bgplvmNormErr)\n",
    "    print 'Corr p-value: PCA: %f, BGPLVM: %f' % (pcaCorr[1],bgplvmCorr[1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# p-values for the test data\n",
    "results['Stats'] = {'Err':{},'Corr':{},'NormErr':{}}\n",
    "\n",
    "pcaTestErr = np.asarray(results['PCA']['Err'][1:])\n",
    "pcaTestCorr = np.asarray(results['PCA']['Corr'][1:])\n",
    "pcaTestNormErr = np.asarray(results['PCA']['NormErr'][1:])\n",
    "\n",
    "bgplvmTestErr = np.asarray(results['BGPLVM']['Err'][1:])\n",
    "bgplvmTestCorr = np.asarray(results['BGPLVM']['Corr'][1:])\n",
    "bgplvmTestNormErr = np.asarray(results['BGPLVM']['NormErr'][1:])\n",
    "\n",
    "tTestErr, pTTestErr = wilcoxon(bgplvmTestErr, pcaTestErr)\n",
    "tTestCorr, pTTestCorr = wilcoxon(bgplvmTestCorr, pcaTestCorr)\n",
    "tTestNormErr, pTTestNormErr = wilcoxon(bgplvmTestNormErr, pcaTestNormErr)\n",
    "\n",
    "results['Stats']['Err']['tStat'] = tTestErr\n",
    "results['Stats']['Err']['pVal'] = pTTestErr\n",
    "results['Stats']['Corr']['tStat'] = tTestCorr\n",
    "results['Stats']['Corr']['pVal'] = pTTestCorr\n",
    "results['Stats']['NormErr']['tStat'] = tTestNormErr\n",
    "results['Stats']['NormErr']['pVal'] = pTTestNormErr\n",
    "print results['Stats']['Err']['pVal'], results['Stats']['NormErr']['pVal'], results['Stats']['Corr']['pVal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save results pickle file\n",
    "pickle.dump(results,open('Result/metricData.p','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "red = Tango.colorsHex['mediumRed']\n",
    "blue = Tango.colorsHex['mediumBlue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotScales(scales, options, yThresh=0.05):\n",
    "    fSize = 30\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    x = np.arange(1,scales.shape[0]+1)\n",
    "    c = 'b'\n",
    "    ax.bar(x, height=scales, width=0.8, align='center', color=blue, edgecolor='k', linewidth=1.3)        \n",
    "    #ax.plot([0.4, scales.shape[0]+0.6], [yThresh, yThresh], '--', linewidth=3, color=red)\n",
    "    \n",
    "    # setting the bar plot parameters\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_xlim(.4, scales.shape[0]+.6)\n",
    "    ax.tick_params(axis='both', labelsize=fSize)\n",
    "    ax.set_xticks(xrange(1,scales.shape[0]+1))\n",
    "    ax.set_title(options['title'], fontsize=fSize)\n",
    "    ax.set_ylabel(options['ylabel'], fontsize=fSize)\n",
    "    ax.set_xlabel('Latent Dimensions', fontsize=fSize)\n",
    "    plt.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pcaLatent(pcaInput, plotIndices = [0,1], maxPoints = [1000,500]):\n",
    "    # plotting variable initialization\n",
    "    s = 100\n",
    "    fSize = 30\n",
    "    resolution = 50\n",
    "\n",
    "    testMarker = 'o'\n",
    "    trainMarker = 'o'\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    # get latent space data\n",
    "    testData = pcaInput[1]    \n",
    "    trainData = pcaInput[0]\n",
    "    \n",
    "    # subsample latent points for easier visualization\n",
    "    if trainData.shape[0] > maxPoints[0]:\n",
    "        sample = np.random.choice(trainData.shape[0], size=maxPoints[0], replace=False)\n",
    "        trainData = trainData[sample]\n",
    "    \n",
    "    if testData.shape[0] > maxPoints[1]:\n",
    "        sample = np.random.choice(testData.shape[0], size=maxPoints[1], replace=False)\n",
    "        testData = testData[sample]\n",
    "    \n",
    "    # labels variable for plotting\n",
    "    testLabels = [red]*testData.shape[0]\n",
    "    trainLabels = [blue]*trainData.shape[0]\n",
    "        \n",
    "    # variables for plotting\n",
    "    qDim = trainData.shape[1]\n",
    "    input1, input2 = plotIndices\n",
    "    nSamples = trainData.shape[0]\n",
    "        \n",
    "    # compute plot limits\n",
    "    xmin, ymin = trainData[:, [input1, input2]].min(0)\n",
    "    xmax, ymax = trainData[:, [input1, input2]].max(0)\n",
    "    x_r, y_r = xmax-xmin, ymax-ymin\n",
    "    xmin -= .1*x_r\n",
    "    xmax += .1*x_r\n",
    "    ymin -= .1*y_r\n",
    "    ymax += .1*y_r\n",
    "\n",
    "    trainHandle = ax.scatter(trainData[:, input1], trainData[:, input2], marker=trainMarker, s=s, c=trainLabels, \n",
    "                            linewidth=.2, edgecolor='k', alpha=1.)\n",
    "    testHandle = ax.scatter(testData[:, input1], testData[:, input2], marker=testMarker, s=s, c=testLabels, \n",
    "                            linewidth=.2, edgecolor='k', alpha=1.)\n",
    "    \n",
    "    ax.grid(b=False)\n",
    "    ax.set_aspect('auto')\n",
    "    ax.legend(['Train','Test'],loc=1)\n",
    "    ax.tick_params(axis='both', labelsize=fSize)\n",
    "    ax.set_xlabel('Latent Dimension %i' % (input1+1), fontsize=fSize)\n",
    "    ax.set_ylabel('Latent Dimension %i' % (input2+1), fontsize=fSize)\n",
    "\n",
    "    ax.set_xlim((xmin, xmax))\n",
    "    ax.set_ylim((ymin, ymax))\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.canvas.draw()\n",
    "    plt.show()\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bgplvmLatent(model, testData, plotIndices = [0,1], maxPoints = [1000,500]):\n",
    "    # plotting variable initialization\n",
    "    s = 100\n",
    "    fSize = 30\n",
    "    resolution = 50\n",
    "\n",
    "    testMarker = 'o'\n",
    "    trainMarker = 'o'\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    # get latent space plot parameters\n",
    "    trainData = model.X.mean\n",
    "    qDim = model.X.mean.shape[1]\n",
    "    input1, input2 = plotIndices\n",
    "    nSamples = model.X.mean.shape[0]\n",
    "    \n",
    "    # subsample latent points for easier visualization\n",
    "    if trainData.shape[0] > maxPoints[0]:\n",
    "        sample = np.random.choice(trainData.shape[0], size=maxPoints[0], replace=False)\n",
    "        trainData = trainData[sample]\n",
    "    \n",
    "    if testData.shape[0] > maxPoints[1]:\n",
    "        sample = np.random.choice(testData.shape[0], size=maxPoints[1], replace=False)\n",
    "        testData = testData[sample]\n",
    "    \n",
    "    \n",
    "    # label variables for plotting\n",
    "    testLabels = [red]*testData.shape[0]\n",
    "    trainLabels = [blue]*trainData.shape[0]\n",
    "    \n",
    "    # compute plot limits\n",
    "    xmin, ymin = trainData[:, [input1, input2]].min(0)\n",
    "    xmax, ymax = trainData[:, [input1, input2]].max(0)\n",
    "    x_r, y_r = xmax-xmin, ymax-ymin\n",
    "    xmin -= .1*x_r\n",
    "    xmax += .1*x_r\n",
    "    ymin -= .1*y_r\n",
    "    ymax += .1*y_r\n",
    "\n",
    "    # plot the variance for the model\n",
    "    def plotFunction(x):\n",
    "        Xtest_full = np.zeros((x.shape[0], qDim))\n",
    "        Xtest_full[:, [input1, input2]] = x\n",
    "        _, var = model.predict(np.atleast_2d(Xtest_full))\n",
    "        var = var[:, :1]\n",
    "        return -np.log(var)\n",
    "\n",
    "    x, y = np.mgrid[xmin:xmax:1j*resolution, ymin:ymax:1j*resolution]\n",
    "    gridData = np.hstack((x.flatten()[:, None], y.flatten()[:, None]))\n",
    "    gridVariance = (plotFunction(gridData)).reshape((resolution, resolution))\n",
    "\n",
    "    varianceHandle = plt.imshow(gridVariance.T, interpolation='bilinear', origin='lower', cmap=cm.gray,\n",
    "                                extent=(xmin, xmax, ymin, ymax))\n",
    "\n",
    "    # test and training plotting\n",
    "    trainHandle = ax.scatter(trainData[:, input1], trainData[:, input2], marker=trainMarker, s=s, c=trainLabels, \n",
    "                            linewidth=.2, edgecolor='k', alpha=1.)\n",
    "    testHandle = ax.scatter(testData[:, input1], testData[:, input2], marker=testMarker, s=s, c=testLabels, \n",
    "                            linewidth=.2, edgecolor='k', alpha=1.)\n",
    "    \n",
    "    ax.grid(b=False)\n",
    "    ax.set_aspect('auto')\n",
    "    ax.legend(['Train','Test'],loc=1)\n",
    "    ax.tick_params(axis='both', labelsize=fSize)\n",
    "    ax.set_xlabel('Latent Dimension %i' % (input1+1), fontsize=fSize)\n",
    "    ax.set_ylabel('Latent Dimension %i' % (input2+1), fontsize=fSize)\n",
    "\n",
    "    ax.set_xlim((xmin, xmax))\n",
    "    ax.set_ylim((ymin, ymax))\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    fig.tight_layout()\n",
    "    fig.canvas.draw()\n",
    "    plt.show()\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to plot error bars\n",
    "def plotErrorBars(mE, sE, xLabels, legend, colors, ylabel='NRMSE', \n",
    "                  legendLoc=1, title='Comparison', ylimit=[0.,1.], \n",
    "                  xlimit=[-0.1,2.1]):\n",
    "    fSize = 30\n",
    "    N = mE.shape[1]\n",
    "    width = 0.8/mE.shape[0]       \n",
    "    \n",
    "    ind = np.arange(N)  \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    for i in range(mE.shape[0]):\n",
    "        err = ax.bar(0.1+ind+i*width, mE[i,:], yerr=sE[i,:], width=width, color=colors[i], ecolor='k')\n",
    "    \n",
    "    ax.set_ylim(ylimit)\n",
    "    ax.set_xlim(xlimit)\n",
    "    ax.set_xticks(ind + 0.5)\n",
    "    ax.set_title(title, fontsize= fSize)\n",
    "    ax.set_ylabel(ylabel, fontsize=fSize)\n",
    "    ax.legend(legend, loc=legendLoc, fontsize=fSize)\n",
    "    ax.set_xticklabels(xLabels, fontsize=fSize)\n",
    "    \n",
    "    for tick in ax.yaxis.get_major_ticks():\n",
    "        tick.label.set_fontsize(fSize)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Plots\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the test data\n",
    "metricData = pickle.load(open('Result/metricData.p','rb'))\n",
    "latentData = pickle.load(open('../Result/Exp1/latentData.p','rb'))\n",
    "predictData = pickle.load(open('../Result/Exp1/predictData.p','rb'))\n",
    "\n",
    "# Performing latent point inference\n",
    "bgplvmModel = pickle.load(open('../Models/Exp1/model.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "options = {'title':'','ylabel':'ARD Weight'}\n",
    "plotScales(latentData['BGPLVMScales'], options)\n",
    "plt.savefig('Result/bgplvmLatentScales.pdf', format='pdf')\n",
    "\n",
    "bgplvmLatent(bgplvmModel, latentData['BGPLVM'])\n",
    "plt.savefig('Result/bgplvmLatentSpace1.pdf', format='pdf')\n",
    "\n",
    "bgplvmLatent(bgplvmModel, latentData['BGPLVM'], plotIndices=[0,2])\n",
    "plt.savefig('Result/bgplvmLatentSpace2.pdf',format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "options = {'title':'','ylabel':'Eigen Value/Variance'}\n",
    "plotScales(latentData['PCAScales'],options,yThresh=0.05)\n",
    "plt.savefig('Result/pcaLatentScales.pdf', format='pdf')\n",
    "\n",
    "pcaPlot = [latentData['PCATrain'],latentData['PCA']]\n",
    "pcaLatent(pcaPlot)\n",
    "plt.savefig('Result/pcaLatentSpace1.pdf', format='pdf')\n",
    "\n",
    "pcaLatent(pcaPlot, plotIndices=[0,2])\n",
    "plt.savefig('Result/pcaLatentSpace2.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Reconstruction Error\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = ['r','b']\n",
    "legend = ['PCA','BGPLVM']\n",
    "xLabels = ['Train','Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcaME = np.asarray([metricData['PCA']['Err'][0],np.asarray(metricData['PCA']['Err'][1:]).mean()])\n",
    "bgplvmME = np.asarray([metricData['BGPLVM']['Err'][0],np.asarray(metricData['BGPLVM']['Err'][1:]).mean()])\n",
    "\n",
    "pcaSE = np.asarray([0.0,np.asarray(metricData['PCA']['Err'][1:]).std()])\n",
    "bgplvmSE = np.asarray([0.0,np.asarray(metricData['BGPLVM']['Err'][1:]).std()])\n",
    "\n",
    "mE = np.asarray([pcaME,bgplvmME])\n",
    "sE = np.asarray([pcaSE,bgplvmSE])\n",
    "ax = plotErrorBars(mE, sE, xLabels, legend, colors, ylabel='RMSE', title='', ylimit=[0.01,0.03], legendLoc=2)\n",
    "\n",
    "x = 1.5\n",
    "y = max(bgplvmME[1]+bgplvmSE[1]/2, pcaME[1]+pcaSE[1]/2)\n",
    "dx = abs(0.4)\n",
    "\n",
    "text = '**'\n",
    "ax.annotate(text, xy=(1.43,1.07*y), fontsize=20, fontweight='bold')\n",
    "props = {'connectionstyle':'bar', 'arrowstyle':'-', 'shrinkA':20, 'shrinkB':20, 'lw':2}\n",
    "ax.annotate('', xy=(1.3,y), xytext=(1.7,y), arrowprops=props)\n",
    "\n",
    "plt.savefig('Result/bgplvmRMSE.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcaME = np.asarray([metricData['PCA']['NormErr'][0],np.asarray(metricData['PCA']['NormErr'][1:]).mean()])\n",
    "bgplvmME = np.asarray([metricData['BGPLVM']['NormErr'][0],np.asarray(metricData['BGPLVM']['NormErr'][1:]).mean()])\n",
    "\n",
    "pcaSE = np.asarray([0.0,np.asarray(metricData['PCA']['NormErr'][1:]).std()])\n",
    "bgplvmSE = np.asarray([0.0,np.asarray(metricData['BGPLVM']['NormErr'][1:]).std()])\n",
    "\n",
    "mE = np.asarray([pcaME,bgplvmME])\n",
    "sE = np.asarray([pcaSE,bgplvmSE])\n",
    "ax = plotErrorBars(mE, sE, xLabels, legend, colors, ylabel='NRMSE', title='', ylimit=[0.05,0.25], legendLoc=2)\n",
    "\n",
    "x = 1.5\n",
    "y = max(bgplvmME[1]+bgplvmSE[1]/2, pcaME[1]+pcaSE[1]/2)\n",
    "dx = abs(0.4)\n",
    "\n",
    "text = '**'\n",
    "ax.annotate(text, xy=(1.43,1.07*y), fontsize=20, fontweight='bold')\n",
    "props = {'connectionstyle':'bar', 'arrowstyle':'-', 'shrinkA':20, 'shrinkB':20, 'lw':2}\n",
    "ax.annotate('', xy=(1.3,y), xytext=(1.7,y), arrowprops=props)\n",
    "\n",
    "plt.savefig('Result/bgplvmNRMSE.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcaMC = np.asarray([metricData['PCA']['Corr'][0],np.asarray(metricData['PCA']['Corr'][1:]).mean()])\n",
    "bgplvmMC = np.asarray([metricData['BGPLVM']['Corr'][0],np.asarray(metricData['BGPLVM']['Corr'][1:]).mean()])\n",
    "\n",
    "pcaSC = np.asarray([0.0,np.asarray(metricData['PCA']['Corr'][1:]).std()])\n",
    "bgplvmSC = np.asarray([0.0,np.asarray(metricData['BGPLVM']['Corr'][1:]).std()])\n",
    "\n",
    "mC = np.asarray([pcaMC,bgplvmMC])\n",
    "sC = np.asarray([pcaSC,bgplvmSC])\n",
    "ax = plotErrorBars(mC, sC, xLabels, legend, colors, ylabel='Correlation', title='', ylimit=[0.5,0.85], legendLoc=1)\n",
    "\n",
    "x = 1.5\n",
    "y = max(bgplvmMC[1]+bgplvmSC[1]/2, pcaMC[1]+pcaSC[1]/2)\n",
    "dx = abs(0.4)\n",
    "\n",
    "text = '**'\n",
    "ax.annotate(text, xy=(1.43,1.05*y), fontsize=20, fontweight='bold')\n",
    "props = {'connectionstyle':'bar', 'arrowstyle':'-', 'shrinkA':20, 'shrinkB':20, 'lw':2}\n",
    "ax.annotate('', xy=(1.3,y), xytext=(1.7,y), arrowprops=props)\n",
    "\n",
    "plt.savefig('Result/bgplvmCorr.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Train p-Val\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pcaErr = [metricData['PCA']['Err'][0],np.asarray(metricData['PCA']['Err'][1:]).mean()]\n",
    "bgplvmErr = [metricData['BGPLVM']['Err'][0],np.asarray(metricData['BGPLVM']['Err'][1:]).mean()]\n",
    "\n",
    "pcaNormErr = [metricData['PCA']['NormErr'][0],np.asarray(metricData['PCA']['NormErr'][1:]).mean()]\n",
    "bgplvmNormErr = [metricData['BGPLVM']['NormErr'][0],np.asarray(metricData['BGPLVM']['NormErr'][1:]).mean()]\n",
    "\n",
    "pcaCorr = [metricData['PCA']['Corr'][0],np.asarray(metricData['PCA']['Corr'][1:]).mean()]\n",
    "bgplvmCorr = [metricData['BGPLVM']['Corr'][0],np.asarray(metricData['BGPLVM']['Corr'][1:]).mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print pcaErr, bgplvmErr, pcaNormErr, bgplvmNormErr, pcaCorr, bgplvmCorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize variables to compute metrics\n",
    "nTrials = len(trainTraj)\n",
    "results = {'PCA':{'Err':[],'Corr':[],'pval':[],'NormErr':[]}, \n",
    "           'BGPLVM':{'Err':[],'Corr':[],'pval':[],'NormErr':[]}}\n",
    "\n",
    "pcaPred = predictData['PCA'][0].copy()\n",
    "bgplvmPred = predictData['BGPLVM'][0].copy()\n",
    "\n",
    "# loop over the trials\n",
    "for nTrial,size in enumerate(trainSizes):\n",
    "    pcaData = pcaPred[:size,:]\n",
    "    trueData = trainTraj[nTrial]\n",
    "    bgplvmData = bgplvmPred[:size,:]\n",
    "\n",
    "    pcaPred = np.delete(pcaPred,(range(size)),axis=0)\n",
    "    bgplvmPred = np.delete(bgplvmPred,(range(size)),axis=0)\n",
    "\n",
    "    pcaNormErr, pcaErr, pcaCorr = computeMetrics(pcaData,trueData)\n",
    "    bgplvmNormErr, bgplvmErr, bgplvmCorr = computeMetrics(bgplvmData,trueData)\n",
    "    \n",
    "    results['PCA']['Err'].append(pcaErr)\n",
    "    results['PCA']['Corr'].append(pcaCorr[0])\n",
    "    results['PCA']['NormErr'].append(pcaNormErr)\n",
    "    \n",
    "    results['BGPLVM']['Err'].append(bgplvmErr)\n",
    "    results['BGPLVM']['Corr'].append(bgplvmCorr[0])\n",
    "    results['BGPLVM']['NormErr'].append(bgplvmNormErr)\n",
    "\n",
    "    print 'Trial: %d' % nTrial\n",
    "    print 'Errs: PCA: %f, BGPLVM: %f' % (pcaErr,bgplvmErr)\n",
    "    print 'Corrs: PCA: %f, BGPLVM: %f' % (pcaCorr[0],bgplvmCorr[0])\n",
    "    print 'Norm Errs: PCA: %f, BGPLVM: %f' % (pcaNormErr,bgplvmNormErr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# p-values for the test data\n",
    "results['Stats'] = {'Err':{},'Corr':{},'NormErr':{}}\n",
    "\n",
    "pcaTrainErr = np.asarray(results['PCA']['Err'])\n",
    "pcaTrainCorr = np.asarray(results['PCA']['Corr'])\n",
    "pcaTrainNormErr = np.asarray(results['PCA']['NormErr'])\n",
    "\n",
    "bgplvmTrainErr = np.asarray(results['BGPLVM']['Err'])\n",
    "bgplvmTrainCorr = np.asarray(results['BGPLVM']['Corr'])\n",
    "bgplvmTrainNormErr = np.asarray(results['BGPLVM']['NormErr'])\n",
    "\n",
    "tTrainErr, pTTrainErr = wilcoxon(bgplvmTrainErr, pcaTrainErr)\n",
    "tTrainCorr, pTTrainCorr = wilcoxon(bgplvmTrainCorr, pcaTrainCorr)\n",
    "tTrainNormErr, pTTrainNormErr = wilcoxon(bgplvmTrainNormErr, pcaTrainNormErr)\n",
    "\n",
    "results['Stats']['Err']['tStat'] = tTrainErr\n",
    "results['Stats']['Err']['pVal'] = pTTrainErr\n",
    "results['Stats']['Corr']['tStat'] = tTrainCorr\n",
    "results['Stats']['Corr']['pVal'] = pTTrainCorr\n",
    "results['Stats']['NormErr']['tStat'] = tTrainNormErr\n",
    "results['Stats']['NormErr']['pVal'] = pTTrainNormErr\n",
    "print results['Stats']['Err']['pVal'], results['Stats']['NormErr']['pVal'], results['Stats']['Corr']['pVal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save results pickle file\n",
    "pickle.dump(results,open('Result/metricData2.p','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
