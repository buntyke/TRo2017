{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 4: TRo Journal\n",
    "---\n",
    "\n",
    "Present predictive and modeling performance of using MRD for cloth state modeling through plots. An example MRD model is trained and various plots such as latent space, ard kernel scales and the test inference results are plotted here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the modules\n",
    "import GPy\n",
    "import csv\n",
    "import sys\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import scipy.stats as stats\n",
    "import sklearn.metrics as metrics\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the overall parameters for bgplvm\n",
    "qDim = 15\n",
    "\n",
    "# dimensions for kinect and mocap\n",
    "qDims = [10,5]\n",
    "qDVals = [np.arange(0,qDims[0]), np.arange(qDims[0],qDims[0]+qDims[1])]\n",
    "\n",
    "# set the number of inducing inputs\n",
    "nTrials = 6\n",
    "nInducing = 100\n",
    "\n",
    "# main loop\n",
    "samplingFreq = 2\n",
    "\n",
    "# optimization variables\n",
    "SNR1 = 100\n",
    "SNR0 = 1000\n",
    "trainIters = 1500\n",
    "initMod0Iters = 500\n",
    "initMod1Iters = 500\n",
    "initVardistIters = 1500\n",
    "\n",
    "# define the observation spaces\n",
    "kinectExt = 'C'\n",
    "kinectDim = 7500\n",
    "kinectKey = 'Cloud'\n",
    "\n",
    "mocapDim = 8\n",
    "mocapExt = 'T'\n",
    "mocapKey = 'TopCoord'\n",
    "\n",
    "# variables for initialization\n",
    "keys = [kinectKey,mocapKey]\n",
    "dims = [kinectDim, mocapDim]\n",
    "YNames = [kinectKey, mocapKey]\n",
    "names = ['K1S1P1T1','K1S1P2T1','K1S1P3T1','K1S1P4T1','K1S1P5T1','K1S1P6T1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize training, test data\n",
    "valData = {}\n",
    "testData = {}\n",
    "trainData = {}\n",
    "\n",
    "testInd = 0\n",
    "trainInd = range(nTrials)\n",
    "del trainInd[testInd]\n",
    "valInd = (testInd+1)%nTrials\n",
    "print valInd, testInd, trainInd\n",
    "    \n",
    "for key,dim in zip(keys,dims):\n",
    "    trD = np.empty((0,dim))\n",
    "    for ind in trainInd:\n",
    "        trD = np.concatenate((trD,Data[names[ind]][key][::samplingFreq,:]),axis=0)\n",
    "    trainData[key] = trD\n",
    "        \n",
    "    valData[key] = Data[names[valInd]][key]\n",
    "    testData[key] = Data[names[testInd]][key]\n",
    "        \n",
    "# choosing the training dataset\n",
    "nSamples = trainData[kinectKey].shape[0]\n",
    "trainList = [trainData[kinectKey], trainData[mocapKey]]\n",
    "print nSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initializing the latent space \n",
    "scales = []\n",
    "inputX = np.zeros((nSamples,qDim))\n",
    "\n",
    "for qD,qDV,Y in zip(qDims, qDVals, trainList):\n",
    "    x,frcs = GPy.util.initialization.initialize_latent('PCA',qD, Y)\n",
    "    scales.extend(frcs)\n",
    "    inputX[:,qDV] = x\n",
    "    \n",
    "scales = np.asarray(scales)\n",
    "    \n",
    "# setting up the kernel\n",
    "mrdKernels = []\n",
    "\n",
    "for Y in trainList:\n",
    "    mrdKernels.append(GPy.kern.RBF(qDim, variance=1., lengthscale=1./scales, ARD = True))\n",
    "        \n",
    "# initializing MRD model\n",
    "mrdModel = GPy.models.MRD(trainList, input_dim=qDim, num_inducing=nInducing, kernel=mrdKernels, X=inputX)\n",
    "print 'Setup Model!'\n",
    "    \n",
    "# Phase 1: Optimizaition by fixing variance parameters\n",
    "var0 = mrdModel.Y0.Y.var()\n",
    "var1 = mrdModel.Y1.Y.var()\n",
    "\n",
    "mrdModel.Y0.rbf.variance.fix(var0)\n",
    "mrdModel.Y1.rbf.variance.fix(var1)\n",
    "\n",
    "mrdModel.Y0.Gaussian_noise.variance.fix(var0/SNR0)\n",
    "mrdModel.Y1.Gaussian_noise.variance.fix(var1/SNR1)\n",
    "\n",
    "mrdModel.optimize(messages=True, max_iters=initVardistIters)\n",
    "    \n",
    "# Phase 2: Optimize each model individually\n",
    "\n",
    "# constrain space 0\n",
    "mrdModel.Y1.constrain_fixed()\n",
    "mrdModel.optimize(messages=True, max_iters=initMod0Iters)\n",
    "\n",
    "# constrain space 1\n",
    "mrdModel.Y0.constrain_fixed()\n",
    "mrdModel.Y1.unconstrain_fixed()\n",
    "mrdModel.Y1.rbf.variance.fix(var1)\n",
    "mrdModel.Y1.Gaussian_noise.variance.fix(var1/SNR1)\n",
    "mrdModel.optimize(messages=True, max_iters=initMod1Iters)\n",
    "    \n",
    "# Phase 3: Optimize the model without any constraints\n",
    "\n",
    "# training without constraints\n",
    "mrdModel.Y0.unconstrain_fixed()\n",
    "mrdModel.Y1.unconstrain_fixed()\n",
    "mrdModel.optimize(messages=True, max_iters=trainIters)\n",
    "    \n",
    "print 'Training Done!'\n",
    "\n",
    "# save the model\n",
    "pickle.dump(mrdModel,open('../Models/Exp4/model.p','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import GPy.plotting.Tango as Tango\n",
    "\n",
    "def plotScales(scales1, scales2, options, yThresh=0.05):\n",
    "    fSize = 20\n",
    "    fig = plt.figure()    \n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    x = np.arange(1,scales1.shape[0]+1)\n",
    "    c1 = Tango.colorsHex['mediumBlue']\n",
    "    c2 = Tango.colorsHex['darkGreen']\n",
    "    h1 = ax.bar(x, height=scales1, width=0.8, align='center', color=c1, edgecolor='k', linewidth=1.3)\n",
    "    h2 = ax.bar(x, height=scales2, width=0.5, align='center', color=c2, edgecolor='k', linewidth=0.7)\n",
    "    ax.plot([0.4, scales1.shape[0]+0.6], [yThresh, yThresh], '--', linewidth=3, color=Tango.colorsHex['mediumRed'])\n",
    "    \n",
    "    # setting the bar plot parameters\n",
    "    ax.set_xlim(.4, scales1.shape[0]+.6)\n",
    "    ax.tick_params(axis='both', labelsize=fSize)\n",
    "    ax.set_xticks(xrange(1,scales1.shape[0]+1))\n",
    "    ax.set_title(options['title'], fontsize=fSize)\n",
    "    ax.set_ylabel(options['ylabel'], fontsize=fSize)\n",
    "    ax.set_xlabel('Latent Dimensions', fontsize=fSize)\n",
    "    ax.legend([h1,h2],options['labels'], loc=2, fontsize=fSize)\n",
    "    plt.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "import GPy.plotting.Tango as Tango\n",
    "\n",
    "def plotLatent(inX, title, model=None, which_indices=[0,1], plot_inducing=False, plot_variance=False, max_points=[800,300]):\n",
    "    \n",
    "    s = 100\n",
    "    fSize = 20\n",
    "    marker = 'o'    \n",
    "    resolution = 50\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    Tango.reset()\n",
    "\n",
    "    input1, input2 = which_indices\n",
    "\n",
    "    if inX[0].shape[0] > max_points[0]:\n",
    "        print(\"Warning\".format(inX[0].shape))\n",
    "        subsample = np.random.choice(inX[0].shape[0], size=max_points[0], replace=False)\n",
    "        inX[0] = inX[0][subsample]\n",
    "\n",
    "    if inX[1].shape[0] > max_points[1]:\n",
    "        print(\"Warning\".format(inX[1].shape))\n",
    "        subsample = np.random.choice(inX[1].shape[0], size=max_points[1], replace=False)\n",
    "        inX[1] = inX[1][subsample]\n",
    "        \n",
    "    xmin, ymin = inX[0][:, [input1, input2]].min(0)\n",
    "    xmax, ymax = inX[0][:, [input1, input2]].max(0)\n",
    "    x_r, y_r = xmax-xmin, ymax-ymin\n",
    "    xmin -= .1*x_r\n",
    "    xmax += .1*x_r\n",
    "    ymin -= .1*y_r\n",
    "    ymax += .1*y_r\n",
    "    print xmin, xmax, ymin, ymax\n",
    "    \n",
    "    if plot_variance:\n",
    "        def plotFunction(x):\n",
    "            Xtest_full = np.zeros((x.shape[0], qDim))\n",
    "            Xtest_full[:, [input1, input2]] = x\n",
    "            _, var = model.predict(np.atleast_2d(Xtest_full))\n",
    "            var = var[:, :1]\n",
    "            return -np.log(var)\n",
    "        qDim = model.X.mean.shape[1]\n",
    "        x, y = np.mgrid[xmin:xmax:1j*resolution, ymin:ymax:1j*resolution]\n",
    "        gridData = np.hstack((x.flatten()[:, None], y.flatten()[:, None]))\n",
    "        gridVariance = (plotFunction(gridData)).reshape((resolution, resolution))\n",
    "        varianceHandle = plt.imshow(gridVariance.T, interpolation='bilinear', origin='lower', cmap=cm.gray,\n",
    "                                    extent=(xmin, xmax, ymin, ymax))\n",
    "        \n",
    "    trainH = ax.scatter(inX[0][:, input1], inX[0][:, input2], marker=marker, s=s, c=Tango.colorsHex['mediumBlue'], linewidth=.2, edgecolor='k', alpha=1.)\n",
    "    testH = ax.scatter(inX[1][:, input1], inX[1][:, input2], marker=marker, s=s, c=Tango.colorsHex['mediumRed'], linewidth=.2, edgecolor='k', alpha=0.9)\n",
    "    \n",
    "    ax.grid(b=False) \n",
    "    ax.set_aspect('auto')\n",
    "    ax.tick_params(axis='both', labelsize=20)\n",
    "    ax.legend([trainH,testH],['Train','Test'],loc=2,fontsize=fSize)\n",
    "    ax.set_xlabel('Latent Dimension %i' % (input1+1), fontsize=fSize)\n",
    "    ax.set_ylabel('Latent Dimension %i' % (input2+1), fontsize=fSize)\n",
    "    \n",
    "    if plot_inducing:\n",
    "        Z = model.Z\n",
    "        ax.scatter(Z[:, input1], Z[:, input2], c='w', s=25, marker=\"^\", edgecolor='k', linewidth=.3, alpha=.6)\n",
    "\n",
    "    ax.set_xlim((xmin, xmax))\n",
    "    ax.set_ylim((ymin, ymax))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Inference\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to compute reconstruction error\n",
    "def reconstructionError(model, valData, testData, mKey, kKey, optimizeFlag=False):    \n",
    "    nSamplesVal = valData[mKey].shape[0]\n",
    "    nSamplesTest = testData[mKey].shape[0]\n",
    "    \n",
    "    nDimIn = valData[kKey].shape[1]\n",
    "    nDimOut = valData[mKey].shape[1]\n",
    "    \n",
    "    qDim = model.X.mean.shape[1]\n",
    "    \n",
    "    # computing reconstruction error for test1, test2 with variances\n",
    "    predictVal = np.zeros((nSamplesVal,nDimOut))\n",
    "    predictTest = np.zeros((nSamplesTest,nDimOut))\n",
    "\n",
    "    latentVal = np.zeros((nSamplesVal,qDim))\n",
    "    latentTest = np.zeros((nSamplesTest,qDim))\n",
    "\n",
    "    for n in range(nSamplesVal):\n",
    "        yIn = valData[kKey][n,:]\n",
    "        yTrueOut = valData[mKey][n,:]\n",
    "    \n",
    "        [xPredict, infX] = model.Y0.infer_newX(yIn[None,:], optimize=False)\n",
    "        yOut = model.predict(xPredict.mean, Yindex=1)    \n",
    "        sys.stdout.write('.')\n",
    "        \n",
    "        predictVal[n,:] = yOut[0]\n",
    "        latentVal[n,:] = xPredict.mean\n",
    "        \n",
    "    sys.stdout.write('\\n')\n",
    "        \n",
    "    for n in range(nSamplesTest):\n",
    "        yIn = testData[kKey][n,:]\n",
    "        yTrueOut = testData[mKey][n,:]\n",
    "    \n",
    "        [xPredict, infX] = model.Y0.infer_newX(yIn[None,:], optimize=optimizeFlag)\n",
    "        yOut = model.predict(xPredict.mean, Yindex=1)    \n",
    "        sys.stdout.write('.')\n",
    "        \n",
    "        predictTest[n,:] = yOut[0]\n",
    "        latentTest[n,:] = xPredict.mean\n",
    "        \n",
    "    sys.stdout.write('\\n')\n",
    "    results = {}\n",
    "    valResults = {}\n",
    "    testResults = {}\n",
    "    \n",
    "    valResults['pred'] = predictVal\n",
    "    testResults['pred'] = predictTest\n",
    "    \n",
    "    valResults['latent'] = latentVal\n",
    "    testResults['latent'] = latentTest\n",
    "    \n",
    "    valErrors = np.sqrt(metrics.mean_squared_error(valData[mKey],predictVal,multioutput='raw_values'))\n",
    "    testErrors = np.sqrt(metrics.mean_squared_error(testData[mKey],predictTest,multioutput='raw_values'))\n",
    "\n",
    "    valNormErrors = np.divide(np.sqrt(metrics.mean_squared_error(valData[mKey],predictVal,multioutput='raw_values')), \n",
    "                              valData[mKey].max(axis=0) - valData[mKey].min(axis=0))\n",
    "    testNormErrors = np.divide(np.sqrt(metrics.mean_squared_error(testData[mKey],predictTest,multioutput='raw_values')), \n",
    "                               testData[mKey].max(axis=0) - testData[mKey].min(axis=0))\n",
    "\n",
    "    valCorr = np.zeros((1,nDimOut))\n",
    "    testCorr = np.zeros((1,nDimOut))\n",
    "    for d in range(dims[1]):\n",
    "        valCorr[0,d],_ = stats.pearsonr(valData[mKey][:,d],predictVal[:,d])\n",
    "        testCorr[0,d],_ = stats.pearsonr(testData[mKey][:,d],predictTest[:,d])\n",
    "\n",
    "    valResults['rmse'] = valErrors\n",
    "    testResults['rmse'] = testErrors\n",
    "    \n",
    "    valResults['nrmse'] = valNormErrors\n",
    "    testResults['nrmse'] = testNormErrors\n",
    "    \n",
    "    valResults['corr'] = valCorr\n",
    "    testResults['corr'] = testCorr\n",
    "        \n",
    "    results['train'] = valResults\n",
    "    results['test'] = testResults\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load main data \n",
    "Data = pickle.load(open('../Data/FeatureData.p','rb'))\n",
    "\n",
    "# create train, val and test data\n",
    "valNames = ['K1S1P2T1']\n",
    "testNames = ['K1S1P1T1']\n",
    "\n",
    "dims = [7500,8,2]\n",
    "samplingFreq = 2\n",
    "keys = ['Cloud','TopCoord','Time']\n",
    "\n",
    "valData = {}\n",
    "testData = {}\n",
    "\n",
    "for key,dim in zip(keys,dims):\n",
    "    vaD = np.empty((0,dim))\n",
    "    teD = np.empty((0,dim))\n",
    "        \n",
    "    for fileName in valNames:\n",
    "        vaD = np.concatenate((vaD,Data[fileName][key]),axis=0)\n",
    "    \n",
    "    for fileName in testNames:\n",
    "        teD = np.concatenate((teD,Data[fileName][key]),axis=0)\n",
    "\n",
    "    valData[key] = vaD\n",
    "    testData[key] = teD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# perform test inference for models\n",
    "mrdModel = pickle.load(open('../Models/Exp4/model.p', 'rb'))\n",
    "mrdResults = reconstructionError(mrdModel,valData,testData,'TopCoord','Cloud',optimizeFlag=True)\n",
    "pickle.dump(mrdResults, open('Result/Results.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Plots\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mrdModel = pickle.load(open('../Models/Exp4/model.p','rb'))\n",
    "mrdResults = pickle.load(open('Result/Results.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the latent scales and latent space\n",
    "scales1 = mrdModel.Y0.kern.input_sensitivity(summarize=False)\n",
    "scales2 = mrdModel.Y1.kern.input_sensitivity(summarize=False)\n",
    "\n",
    "scales1 = scales1/scales1.max()\n",
    "scales2 = scales2/scales2.max()\n",
    "\n",
    "options = {'title':'','ylabel':'ARD Weight','labels':['PointCloud','TopCoord']}\n",
    "plotScales(scales1,scales2,options)\n",
    "plt.savefig('Result/LatentScales.pdf', format='pdf')\n",
    "\n",
    "testX = mrdResults['test']['latent']\n",
    "trainX = mrdModel.X.mean \n",
    "\n",
    "mrdX = [trainX, testX]\n",
    "plotLatent(mrdX, 'Latent Space', model=mrdModel.Y0, which_indices=[11,12], plot_variance=True, max_points=[2000,700])\n",
    "plt.savefig('Result/LatentSpace.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize predictive performance of MRD for test trajectory\n",
    "fSize = 20\n",
    "lWidth = 4\n",
    "mKey = 'TopCoord'\n",
    "time = testData['Time'][:,1]\n",
    "nSamplesTest = testData[mKey].shape[0]\n",
    "predictTest = mrdResults['test']['pred']\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(time,testData[mKey][:,1],c='k',linewidth=lWidth)\n",
    "plt.plot(time,predictTest[:,1],c='b',linewidth=lWidth)\n",
    "plt.title('Collar-Head', fontsize=fSize)\n",
    "plt.xlabel('Time (secs)', fontsize=fSize)\n",
    "plt.tick_params(axis='both', labelsize=fSize)\n",
    "plt.ylabel('Center of Twist', fontsize=fSize)\n",
    "plt.legend(['True','Predict'], fontsize=fSize-5, loc=4)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Result/Inference1.pdf', format='pdf')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(time,testData[mKey][:,2],c='k',linewidth=lWidth)\n",
    "plt.plot(time,predictTest[:,2],c='b',linewidth=lWidth)\n",
    "plt.ylabel('Writhe', fontsize=fSize)\n",
    "plt.title('Collar-Body', fontsize=fSize)\n",
    "plt.xlabel('Time (secs)', fontsize=fSize)\n",
    "plt.tick_params(axis='both', labelsize=fSize)\n",
    "#plt.legend(['True','Predict'], fontsize=fSize)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Result/Inference2.pdf', format='pdf')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(time,testData[mKey][:,5],c='k',linewidth=lWidth)\n",
    "plt.plot(time,predictTest[:,5],c='b',linewidth=lWidth)\n",
    "plt.xlabel('Time (secs)', fontsize=fSize)\n",
    "plt.title('Left Sleeve-Arm', fontsize=fSize)\n",
    "plt.tick_params(axis='both', labelsize=fSize)\n",
    "plt.ylabel('Center of Twist', fontsize=fSize)\n",
    "#plt.legend(['True','Predict'], fontsize=fSize, loc=5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Result/Inference3.pdf', format='pdf')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(time,testData[mKey][:,7],c='k',linewidth=lWidth)\n",
    "plt.plot(time,predictTest[:,7],c='b',linewidth=lWidth)\n",
    "plt.xlabel('Time (secs)', fontsize=fSize)\n",
    "plt.title('Right Arm-Sleeve', fontsize=fSize)\n",
    "plt.tick_params(axis='both', labelsize=fSize)\n",
    "plt.ylabel('Center of Twist', fontsize=fSize)\n",
    "#plt.legend(['True','Predict'], fontsize=fSize, loc=5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Result/Inference4.pdf', format='pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "widgets": {
   "state": {
    "009c1bec69534209bfbd09ae8bfe3630": {
     "views": []
    },
    "06b3e2d22e2c4067a7912b3b537ec5c4": {
     "views": []
    },
    "09ed5791abb640e68a39b7e3d1b0de8d": {
     "views": []
    },
    "0e2c81a987db4961927d17f8b8007ea1": {
     "views": []
    },
    "10da87b4be4245958f608c0877569285": {
     "views": []
    },
    "15e1f329de0342e2a51c38682f2d0b0b": {
     "views": []
    },
    "1ef8b33b9f7c4629b13aeb90dc7ff364": {
     "views": []
    },
    "2577b7a97a684f1794bb227bda8930dd": {
     "views": []
    },
    "271ad9e499144d1b94dec14551459f72": {
     "views": []
    },
    "2c909c416f204e25a7e817bd15e822cb": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "2f5cbe5d834548ffa7c21cb6184b536c": {
     "views": []
    },
    "3d651f80ce2f4ea6afb7ebeec5584f88": {
     "views": []
    },
    "443edbf6e1d348cb96a7a1e57093b16a": {
     "views": []
    },
    "443fdcaa1b244b9fb6d2342228c47bdb": {
     "views": []
    },
    "47be0beceff344b5b3a604403da04ef6": {
     "views": []
    },
    "5be1534c07cc4e0fbc2916d8e016f5ff": {
     "views": []
    },
    "5dfbe3848d504afd9ad6873fd0eea2bc": {
     "views": []
    },
    "744a847723c44f9eb6644ca6abed6f36": {
     "views": []
    },
    "7926033d152947659aec11477ad99605": {
     "views": []
    },
    "7f7a62bac8a44f0eb004040f0b303e91": {
     "views": []
    },
    "88cde9a0157a4d5b8623467acca9ff25": {
     "views": []
    },
    "8959368389bd4147850a9909bfb8a243": {
     "views": []
    },
    "895e7d04ab8f46bcb0e0d15ee00fa053": {
     "views": []
    },
    "91c027a91b2a446592baf6d06a8132d6": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "92f8391043d646c1a1c907b5d77395ed": {
     "views": []
    },
    "a18583f7b2fd4f728fc99f372d3497b5": {
     "views": []
    },
    "a9e4e0c0f99444ab9fcad674d067d8a7": {
     "views": []
    },
    "b0cb84ac75504a5e9197e66832dce50b": {
     "views": []
    },
    "b4b14415520c4ff684ed3ec42a62623f": {
     "views": []
    },
    "bb67e27060e54b279000e3ac68c1df62": {
     "views": []
    },
    "bcb183e16b8e449a98fbe01d1b468dda": {
     "views": []
    },
    "c013dda5902340d8834cb4b7b15eace7": {
     "views": []
    },
    "c56caa1716e8419d87925f20cb8a90e8": {
     "views": []
    },
    "c9a536f79138446aa86c33fcc808e70e": {
     "views": []
    },
    "cb91445c1376426eb8eab3cc3733c83f": {
     "views": []
    },
    "d19f45709956494cb6f38af2bae2c136": {
     "views": []
    },
    "d1bb41bc0fdc484385c6f58d7caa186d": {
     "views": []
    },
    "d391d0077a2e4367ae0425f58c81228b": {
     "views": []
    },
    "d64319fe52f846dc9b1ee0639e433241": {
     "views": []
    },
    "dc24f9910c214cb9929f168010dc80b6": {
     "views": []
    },
    "df1f92f979ca4f1c8ab628929aaf2ced": {
     "views": []
    },
    "e14c2479d3e04592b34b70d69964cd93": {
     "views": []
    },
    "e53d14b8e6c74f198b97df65eb4b0cf2": {
     "views": []
    },
    "e65f648499994f1a893603908027df56": {
     "views": []
    },
    "e7143515be82491d95a16d92eaadb519": {
     "views": []
    },
    "edbe21c473dc4d43b7876b33a70e3b37": {
     "views": []
    },
    "f41c3b2691c24ac2bdb34edc46cd81e8": {
     "views": []
    },
    "fe8bf9bb602e430eba0208a237f9a394": {
     "views": []
    }
   },
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
