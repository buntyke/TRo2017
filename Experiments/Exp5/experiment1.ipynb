{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 5: TRo Journal\n",
    "---\n",
    "\n",
    "Compare the predictive performance of using MRD with various feature representations for the feature space and the observation space.\n",
    "\n",
    "In this Ipython notebook, the predictive performance of 3 different feature representations of each observation space are evaluated. The metrics for evaluation are RMS error, normalized RMS error and pearson correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the modules\n",
    "import GPy\n",
    "import csv\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load all the files and create Data\n",
    "trackPath = '../Data/Tracks/'\n",
    "mocapPath = '../Data/MocapData/'\n",
    "kinectPath = '../Data/KinectData/'\n",
    "\n",
    "names = ['K1S1P1T1','K1S1P2T1','K1S1P3T1','K1S1P4T1','K1S1P5T1','K1S1P6T1']\n",
    "\n",
    "nTypes = 9\n",
    "\n",
    "dataFormats = ['','ESF','Cloud','Color','Depth','Marker','CircleParam','CircleMarker','TopCoord']\n",
    "dataKeys = ['Time','ESF','Cloud','Color','Depth','Marker','CircleParam','CircleMarker','TopCoord']\n",
    "\n",
    "paths = [trackPath, kinectPath, kinectPath, kinectPath, kinectPath, mocapPath, mocapPath, mocapPath, mocapPath]\n",
    "\n",
    "# read all the file names and save to dicts\n",
    "Data = {}\n",
    "# loop over all names\n",
    "for fileName in names:\n",
    "    data = {}\n",
    "    for ind in range(nTypes):\n",
    "        dataName = paths[ind] + fileName + dataFormats[ind] \n",
    "        reader = csv.reader(open(dataName,\"rb\"), delimiter=',')\n",
    "\n",
    "        d = np.array(list(reader))\n",
    "        if ind in [3,4]:\n",
    "            data[dataKeys[ind]] = d.astype('int')\n",
    "        else:\n",
    "            data[dataKeys[ind]] = d.astype('float')        \n",
    "    Data[fileName] = data\n",
    "pickle.dump(Data,open('../Data/FeatureData.p','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the overall parameters for bgplvm\n",
    "qDim = 15\n",
    "\n",
    "# dimensions for kinect and mocap\n",
    "qDims = [10,5]\n",
    "qDVals = [np.arange(0,qDims[0]), np.arange(qDims[0],qDims[0]+qDims[1])]\n",
    "\n",
    "# set the number of inducing inputs\n",
    "nInducing = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# main loop\n",
    "samplingFreq = 2\n",
    "nTrials = len(names)\n",
    "kinectKeys = ['ESF','Color','Depth']\n",
    "mocapKeys = ['Marker','CircleMarker','CircleParam']\n",
    "\n",
    "# optimization variables\n",
    "SNR0 = 1000\n",
    "SNR1 = 100\n",
    "trainIters = 1000\n",
    "initMod0Iters = 500\n",
    "initMod1Iters = 500\n",
    "initVardistIters = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loop over the kinect keys\n",
    "kinectExts = ['E','CO','D']\n",
    "kinectDims = [640,2500,2500]\n",
    "\n",
    "for kinectKey, kinectExt, kinectDim in zip(kinectKeys, kinectExts, kinectDims):\n",
    "    mocapKey = 'TopCoord'\n",
    "    keys = [kinectKey,mocapKey]\n",
    "\n",
    "    # model name\n",
    "    expName = '%sT' % (kinectExt)\n",
    "\n",
    "    # YNames variable\n",
    "    YNames = [kinectKey, mocapKey]\n",
    "    \n",
    "    dims = [kinectDim, 8]\n",
    "\n",
    "    print 'Modality: %s' % (kinectKey)\n",
    "    print kinectKey, kinectExt, kinectDim\n",
    "    \n",
    "    for K in range(nTrials):\n",
    "        valData = {}\n",
    "        testData = {}\n",
    "        trainData = {}\n",
    "\n",
    "        testInd = K\n",
    "        trainInd = range(nTrials)\n",
    "        del trainInd[K]\n",
    "        valInd = (K+1)%nTrials\n",
    "    \n",
    "        print 'Cycle:%d' % (K+1)\n",
    "        print valInd, testInd, trainInd\n",
    "    \n",
    "        for key,dim in zip(keys,dims):\n",
    "            vaD = np.empty((0,dim))\n",
    "            trD = np.empty((0,dim))\n",
    "            teD = np.empty((0,dim))\n",
    "    \n",
    "            for ind in trainInd:\n",
    "                trD = np.concatenate((trD,Data[names[ind]][key]),axis=0)\n",
    "        \n",
    "            vaD = np.concatenate((vaD,Data[names[valInd]][key]),axis=0)\n",
    "            teD = np.concatenate((teD,Data[names[testInd]][key]),axis=0)\n",
    "\n",
    "            valData[key] = vaD\n",
    "            testData[key] = teD\n",
    "            trainData[key] = trD\n",
    "        \n",
    "        # choosing the training dataset\n",
    "        nSamples = trainData[kinectKey].shape[0]\n",
    "        trainList = [trainData[kinectKey], trainData[mocapKey]]\n",
    "    \n",
    "        # initializing the latent space \n",
    "        scales = []\n",
    "        inputX = np.zeros((nSamples,qDim))\n",
    "\n",
    "        for qD,qDV,Y in zip(qDims, qDVals, trainList):\n",
    "            x,frcs = GPy.util.initialization.initialize_latent('PCA',qD, Y)\n",
    "            scales.extend(frcs)\n",
    "            inputX[:,qDV] = x\n",
    "    \n",
    "        scales = np.asarray(scales)\n",
    "        print scales\n",
    "    \n",
    "        # setting up the kernel\n",
    "        mrdKernels = []\n",
    "\n",
    "        for Y in trainList:\n",
    "            mrdKernels.append(GPy.kern.RBF(qDim, variance=1., lengthscale=1./scales, ARD = True))\n",
    "        \n",
    "        # initializing MRD model\n",
    "        mrdModel = GPy.models.MRD(trainList, input_dim=qDim, num_inducing=nInducing, kernel=mrdKernels, \n",
    "                                  X=inputX, name='%s%d' % (expName,K))\n",
    "\n",
    "        print 'Setup Model!'\n",
    "    \n",
    "        # Phase 1: Optimizaition by fixing variance parameters\n",
    "        var0 = mrdModel.Y0.Y.var()\n",
    "        var1 = mrdModel.Y1.Y.var()\n",
    "\n",
    "        mrdModel.Y0.rbf.variance.fix(var0)\n",
    "        mrdModel.Y1.rbf.variance.fix(var1)\n",
    "\n",
    "        mrdModel.Y0.Gaussian_noise.variance.fix(var0/SNR0)\n",
    "        mrdModel.Y1.Gaussian_noise.variance.fix(var1/SNR1)\n",
    "\n",
    "        mrdModel.optimize(messages=True, max_iters=initVardistIters)\n",
    "    \n",
    "        # Phase 2: Optimize each model individually\n",
    "\n",
    "        # constrain space 0\n",
    "        mrdModel.Y1.constrain_fixed()\n",
    "        mrdModel.optimize(messages=True, max_iters=initMod0Iters)\n",
    "\n",
    "        # constrain space 1\n",
    "        mrdModel.Y0.constrain_fixed()\n",
    "        mrdModel.Y1.unconstrain_fixed()\n",
    "        mrdModel.Y1.rbf.variance.fix(var1)\n",
    "        mrdModel.Y1.Gaussian_noise.variance.fix(var1/SNR1)\n",
    "        mrdModel.optimize(messages=True, max_iters=initMod1Iters)\n",
    "    \n",
    "        # Phase 3: Optimize the model without any constraints\n",
    "\n",
    "        # training without constraints\n",
    "        mrdModel.Y0.unconstrain_fixed()\n",
    "        mrdModel.Y1.unconstrain_fixed()\n",
    "        mrdModel.optimize(messages=True, max_iters=trainIters)\n",
    "    \n",
    "        print 'Training Done!'\n",
    "    \n",
    "        # plot the learned model\n",
    "        mrdModel.plot_scales(sharex=True,sharey=False,titles=YNames)\n",
    "        mrdModel.plot_latent(which_indices=[0,1])\n",
    "    \n",
    "        # save the model\n",
    "        mrdModel = pickle.dump(mrdModel, open('../Models/Exp5/%s%d.p' % (expName,K+1),'wb'))\n",
    "    \n",
    "        print 'Saving Done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loop over the mocap keys\n",
    "mocapExts = ['M','CM','CP']\n",
    "for mocapKey, mocapExt in zip(mocapKeys, mocapExts):\n",
    "    kinectKey = 'Cloud'\n",
    "    keys = [kinectKey,mocapKey]\n",
    "\n",
    "    # model name\n",
    "    expName = 'C%s' % (mocapExt)\n",
    "\n",
    "    # YNames variable\n",
    "    YNames = [kinectKey, mocapKey]\n",
    "\n",
    "    for K in range(nTrials):\n",
    "        valData = {}\n",
    "        testData = {}\n",
    "        trainData = {}\n",
    "\n",
    "        testInd = K\n",
    "        trainInd = range(nTrials)\n",
    "        del trainInd[K]\n",
    "        valInd = (K+1)%nTrials\n",
    "    \n",
    "        print 'Cycle:%d' % (K+1)\n",
    "        print valInd, testInd, trainInd\n",
    "    \n",
    "        for key,dim in zip(keys,dims):\n",
    "            vaD = np.empty((0,dim))\n",
    "            trD = np.empty((0,dim))\n",
    "            teD = np.empty((0,dim))\n",
    "    \n",
    "            for ind in trainInd:\n",
    "                trD = np.concatenate((trD,Data[names[ind]][key][::samplingFreq,:]),axis=0)\n",
    "        \n",
    "            vaD = np.concatenate((vaD,Data[names[valInd]][key]),axis=0)\n",
    "            teD = np.concatenate((teD,Data[names[testInd]][key]),axis=0)\n",
    "\n",
    "            valData[key] = vaD\n",
    "            testData[key] = teD\n",
    "            trainData[key] = trD\n",
    "        \n",
    "        # choosing the training dataset\n",
    "        nSamples = trainData[kinectKey].shape[0]\n",
    "        trainList = [trainData[kinectKey], trainData[mocapKey]]\n",
    "    \n",
    "        # initializing the latent space \n",
    "        scales = []\n",
    "        inputX = np.zeros((nSamples,qDim))\n",
    "\n",
    "        for qD,qDV,Y in zip(qDims, qDVals, trainList):\n",
    "            x,frcs = GPy.util.initialization.initialize_latent('PCA',qD, Y)\n",
    "            scales.extend(frcs)\n",
    "            inputX[:,qDV] = x\n",
    "    \n",
    "        scales = np.asarray(scales)\n",
    "        print scales\n",
    "    \n",
    "        # setting up the kernel\n",
    "        mrdKernels = []\n",
    "\n",
    "        for Y in trainList:\n",
    "            mrdKernels.append(GPy.kern.RBF(qDim, variance=1., lengthscale=1./scales, ARD = True))\n",
    "        \n",
    "        # initializing MRD model\n",
    "        mrdModel = GPy.models.MRD(trainList, input_dim=qDim, num_inducing=nInducing, kernel=mrdKernels, \n",
    "                                  X=inputX, name='%s%d' % (expName,K))\n",
    "\n",
    "        print 'Setup Model!'\n",
    "    \n",
    "        # Phase 1: Optimizaition by fixing variance parameters\n",
    "        var0 = mrdModel.Y0.Y.var()\n",
    "        var1 = mrdModel.Y1.Y.var()\n",
    "\n",
    "        mrdModel.Y0.rbf.variance.fix(var0)\n",
    "        mrdModel.Y1.rbf.variance.fix(var1)\n",
    "\n",
    "        mrdModel.Y0.Gaussian_noise.variance.fix(var0/SNR0)\n",
    "        mrdModel.Y1.Gaussian_noise.variance.fix(var1/SNR1)\n",
    "\n",
    "        mrdModel.optimize(messages=True, max_iters=initVardistIters)\n",
    "    \n",
    "        # Phase 2: Optimize each model individually\n",
    "\n",
    "        # constrain space 0\n",
    "        mrdModel.Y1.constrain_fixed()\n",
    "        mrdModel.optimize(messages=True, max_iters=initMod0Iters)\n",
    "\n",
    "        # constrain space 1\n",
    "        mrdModel.Y0.constrain_fixed()\n",
    "        mrdModel.Y1.unconstrain_fixed()\n",
    "        mrdModel.Y1.rbf.variance.fix(var1)\n",
    "        mrdModel.Y1.Gaussian_noise.variance.fix(var1/SNR1)\n",
    "        mrdModel.optimize(messages=True, max_iters=initMod1Iters)\n",
    "    \n",
    "        # Phase 3: Optimize the model without any constraints\n",
    "\n",
    "        # training without constraints\n",
    "        mrdModel.Y0.unconstrain_fixed()\n",
    "        mrdModel.Y1.unconstrain_fixed()\n",
    "        mrdModel.optimize(messages=True, max_iters=trainIters)\n",
    "    \n",
    "        print 'Training Done!'\n",
    "    \n",
    "        # plot the learned model\n",
    "        mrdModel.plot_scales(sharex=True,sharey=False,titles=YNames)\n",
    "        mrdModel.plot_latent(which_indices=[0,1])\n",
    "    \n",
    "        # save the model\n",
    "        mrdModel = pickle.dump(mrdModel, open('../Models/Exp5/%s%d.p' % (expName,K+1),'wb'))\n",
    "    \n",
    "        print 'Saving Done!'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
